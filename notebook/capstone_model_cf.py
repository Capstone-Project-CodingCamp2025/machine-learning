# -*- coding: utf-8 -*-
"""Capstone-Model-CF.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MurgSvbQGpDz-Nuxqyr6FRdZMYheVll9

# **1. Import Library**
"""

import os
import json

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder

"""# **2. Load Dataset**"""

df = pd.read_csv('/content/CF.csv')

"""# **3. EDA**"""

print(df['rating'].describe())
plt.figure(figsize=(6,4))
sns.histplot(df['rating'], bins=10, kde=True)
plt.title('Distribution of Ratings')
plt.xlabel('Rating')
plt.ylabel('Count')
plt.tight_layout()
plt.show()

# Interaksi per user/item
users_count = df['user_id'].value_counts().head(10)
items_count = df['item_id'].value_counts().head(10)
print("Top 10 users by interactions:\n", users_count)
print("Top 10 items by interactions:\n", items_count)

"""# **4. Preprocessing: Label Encoding**"""

user_encoder = LabelEncoder()
item_encoder = LabelEncoder()

df['user_idx'] = user_encoder.fit_transform(df['user_id'])
df['item_idx'] = item_encoder.fit_transform(df['item_id'])

num_users = df['user_idx'].nunique()
num_items = df['item_idx'].nunique()
print(f"ðŸ”¢ Users: {num_users}, Items: {num_items}")

"""# **5. Data Splitting**"""

train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)

BATCH_SIZE = 64

def df_to_tf_dataset(dataframe):
    ds = tf.data.Dataset.from_tensor_slices(({
        'user_idx': dataframe['user_idx'].values,
        'item_idx': dataframe['item_idx'].values
    }, dataframe['rating'].values.astype(np.float32)))
    return ds.shuffle(10000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)

train_ds = df_to_tf_dataset(train_df)
test_ds = df_to_tf_dataset(test_df)

"""# **6. Model Building**"""

EMBEDDING_SIZE = 32
L2_REG = 1e-6

# Inputs
user_input = tf.keras.layers.Input(shape=(), name='user_idx', dtype=tf.int32)
item_input = tf.keras.layers.Input(shape=(), name='item_idx', dtype=tf.int32)

# Embeddings + regularizer
user_emb = tf.keras.layers.Embedding(
    input_dim=num_users,
    output_dim=EMBEDDING_SIZE,
    embeddings_regularizer=tf.keras.regularizers.l2(L2_REG),
    name='user_emb'
)(user_input)

item_emb = tf.keras.layers.Embedding(
    input_dim=num_items,
    output_dim=EMBEDDING_SIZE,
    embeddings_regularizer=tf.keras.regularizers.l2(L2_REG),
    name='item_emb'
)(item_input)

# Bias terms
user_bias = tf.keras.layers.Embedding(num_users, 1, name='user_bias')(user_input)
item_bias = tf.keras.layers.Embedding(num_items, 1, name='item_bias')(item_input)

# Flatten all
user_vec  = tf.keras.layers.Flatten()(user_emb)
item_vec  = tf.keras.layers.Flatten()(item_emb)
user_b    = tf.keras.layers.Flatten()(user_bias)
item_b    = tf.keras.layers.Flatten()(item_bias)

# Dot + bias â†’ output
dot = tf.keras.layers.Dot(axes=1)([user_vec, item_vec])
x   = tf.keras.layers.Add()([dot, user_b, item_b])
output = tf.keras.layers.Activation('linear')(x)

model = tf.keras.Model(inputs=[user_input, item_input], outputs=output)

model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),
    loss='mse',
    metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')]
)

model.summary()

"""# **7. Model training**"""

early_stop = tf.keras.callbacks.EarlyStopping(
    monitor='val_loss',
    patience=3,
    restore_best_weights=True
)

history = model.fit(
    train_ds,
    validation_data=test_ds,
    epochs=50,
    callbacks=[early_stop],
    verbose=1
)

"""# **8. Evaluasi**"""

plt.figure(figsize=(6,4))
plt.plot(history.history['rmse'], label='train RMSE')
plt.plot(history.history['val_rmse'], label='val RMSE')
plt.xlabel('Epoch')
plt.ylabel('RMSE')
plt.legend()
plt.tight_layout()
plt.show()

loss, rmse = model.evaluate(test_ds)
print(f"ðŸ“‰ Test RMSE: {rmse:.4f}")

"""# **9. Simpan Model**"""

os.makedirs('model/cf', exist_ok=True)
model.export('model/cf', include_optimizer=False)
print("âœ… SavedModel ready at model/cf")

!pip install tensorflowjs
!tensorflowjs_converter --input_format=tf_saved_model model/cf model/tfjs_model/
print("âœ… TFJS model ready at model/tfjs_model/")

os.makedirs('model', exist_ok=True)
user_map = {k: int(v) for k, v in zip(user_encoder.classes_, user_encoder.transform(user_encoder.classes_))}
item_map = {k: int(v) for k, v in zip(item_encoder.classes_, item_encoder.transform(item_encoder.classes_))}
with open('model/user_encoder.json', 'w') as f:
    json.dump(user_map, f)
with open('model/item_encoder.json', 'w') as f:
    json.dump(item_map, f)
print("âœ… Encoders saved to model/*.json")

!pip freeze > model/requirements.txt
print("âœ… Saved requirements.txt")

import shutil

# Zip folder model menjadi cbf_encoder.zip
shutil.make_archive('model_cf', 'zip', 'model')

from google.colab import files
files.download('model_cf.zip')

"""# **10. Inference**"""

def predict_rating_py(user_id, item_id):
    """
    Prediksi rating single user-item menggunakan SavedModel + mapping JSON.
    """
    # Cek mapping
    if user_id not in user_map:
        raise ValueError(f"User '{user_id}' tidak dikenali.")
    if item_id not in item_map:
        raise ValueError(f"Item '{item_id}' tidak dikenali.")

    # Ambil index
    u_idx = np.array([user_map[user_id]], dtype=np.int32)
    i_idx = np.array([item_map[item_id]], dtype=np.int32)

    # Predict
    pred = model.predict({'user_idx': u_idx, 'item_idx': i_idx}, verbose=0)
    return float(pred[0])

# Contoh pemakaian
if __name__ == '__main__':
    test_user = df['user_id'].iloc[0]
    test_item = df['item_id'].iloc[0]
    rating = predict_rating_py(test_user, test_item)
    print(f"ðŸŽ¯ Predicted rating for '{test_user}' on '{test_item}': {rating:.2f}")